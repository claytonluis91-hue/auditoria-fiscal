import streamlit as st
import pandas as pd
import json
import xml.etree.ElementTree as ET
import requests
from bs4 import BeautifulSoup
import re

# --- 1. CONFIGURA칂츾O DA P츼GINA ---
st.set_page_config(
    page_title="Auditoria Fiscal - Reforma Tribut치ria (Live)",
    page_icon="丘뒲잺",
    layout="wide"
)

st.title("丘뒲잺 Auditoria Fiscal & An치lise Legal (Online)")
st.markdown("""
**Vers칚o Conectada:** O sistema busca as regras no JSON e cruza com o texto oficial da **LCP 214/2025** direto do site do Planalto.
""")
st.divider()

# --- 2. CARREGAMENTO DE DADOS ---

@st.cache_data
def carregar_regras():
    try:
        with open('classificacao_tributaria.json', 'r', encoding='utf-8') as f:
            dados = json.load(f)
            df = pd.DataFrame(dados)
            df['Busca'] = df['Descri칞칚o do C칩digo da Classifica칞칚o Tribut치ria'].str.lower()
            return df
    except FileNotFoundError:
        return pd.DataFrame()

@st.cache_data
def carregar_texto_lei_online():
    # URL Oficial da Lei Complementar 214
    url = "https://www.planalto.gov.br/ccivil_03/leis/lcp/lcp214.htm"
    
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status() # Garante que o site respondeu
        
        # Limpeza do HTML (BeautifulSoup)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove scripts e estilos CSS para pegar s칩 o texto puro
        for script in soup(["script", "style"]):
            script.extract()
            
        texto_limpo = soup.get_text(separator=' ')
        
        # Remove excesso de espa칞os
        texto_limpo = re.sub(r'\s+', ' ', texto_limpo).lower()
        
        return texto_limpo
    except Exception as e:
        st.error(f"Erro ao acessar site do Planalto: {e}")
        return None

# --- 3. L칍GICA DE INTELIG칅NCIA ---

def limpar_descricao(descricao):
    desc = descricao.lower()
    desc = re.sub(r'[0-9]', '', desc) 
    desc = desc.replace('.', '').replace('-', '')
    palavras_ignoradas = ['kg', 'un', 'pct', 'cx', 'lt', 'ml', 'g', 'garrafa', 'pote']
    palavras = [p for p in desc.split() if p not in palavras_ignoradas and len(p) > 2]
    return " ".join(palavras)

def verificar_na_lei(produto, texto_lei):
    if not texto_lei:
        return "-"
    
    termo_busca = limpar_descricao(produto)
    
    if len(termo_busca) < 4: # Ignora palavras muito curtas
        return "-"

    if termo_busca in texto_lei:
        index = texto_lei.find(termo_busca)
        inicio = max(0, index - 80)
        fim = min(len(texto_lei), index + 80)
        trecho = texto_lei[inicio:fim]
        return f"...{trecho}..."
    
    return "-"

def classificar_item(ncm, cfop, df_regras):
    ncm = str(ncm)
    cfop = str(cfop).replace('.', '')
    
    termo_busca = ""
    status = "PADRAO" 

    if cfop.startswith('7'): 
        termo_busca = "exporta칞칚o"
        status = "IMUNE"
    elif cfop in ['6109', '6110', '5109', '5110']:
        termo_busca = "zona franca"
        status = "BENEFICIO"
    elif cfop in ['5901', '5902', '5949', '6901']:
        return '-', 'Remessa/Devolu칞칚o', 'OUTROS', '999'
        
    elif ncm.startswith('30'):
        termo_busca = "medicamentos"
        status = "REDUZIDA"
    elif ncm.startswith('1006') or ncm.startswith('02') or ncm.startswith('1101'):
        termo_busca = "cesta b치sica"
        status = "ZERO"
    elif ncm.startswith('3304') or ncm.startswith('3401'):
        termo_busca = "higiene"
        status = "REDUZIDA"
    elif ncm.startswith('2710'):
        termo_busca = "combust칤veis"
        status = "MONOFASICA"
    else:
        termo_busca = "tributa칞칚o integral"
        status = "PADRAO"

    if not df_regras.empty:
        resultado = df_regras[df_regras['Busca'].str.contains(termo_busca, na=False)]
        if not resultado.empty:
            codigo = resultado.iloc[0]['C칩digo da Classifica칞칚o Tribut치ria']
            desc = resultado.iloc[0]['Descri칞칚o do C칩digo da Classifica칞칚o Tribut치ria']
            cst = resultado.iloc[0].get('C칩digo da Situa칞칚o Tribut치ria', '?')
            return codigo, desc, status, cst
    
    return 'VERIFICAR', f'Regra n칚o achada: {termo_busca}', 'ATENCAO', '?'

# --- 4. INTERFACE ---
with st.sidebar:
    st.header("游늭 Arquivos")
    uploaded_files = st.file_uploader("XMLs de Venda", type=['xml'], accept_multiple_files=True)
    st.success("游릭 Conectado  Base Legal do Planalto")

df_regras = carregar_regras()
texto_lei = carregar_texto_lei_online() # Acessa a internet aqui

if uploaded_files:
    if df_regras.empty:
        st.error("游뚿 JSON de regras n칚o encontrado.")
    else:
        with st.spinner('Lendo XMLs e Baixando Lei do Planalto...'):
            # Processamento dos XMLs
            lista_produtos = []
            ns = {'ns': 'http://www.portalfiscal.inf.br/nfe'}
            
            for arquivo in uploaded_files:
                try:
                    tree = ET.parse(arquivo)
                    root = tree.getroot()
                    det_itens = root.findall('.//ns:det', ns)
                    for item in det_itens:
                        prod = item.find('ns:prod', ns)
                        try: vProd = float(prod.find('ns:vProd', ns).text)
                        except: vProd = 0.0
                        lista_produtos.append({
                            'NCM': prod.find('ns:NCM', ns).text,
                            'Produto': prod.find('ns:xProd', ns).text,
                            'CFOP': prod.find('ns:CFOP', ns).text,
                            'Valor': vProd
                        })
                except: continue
            
            df_base = pd.DataFrame(lista_produtos)
            
            if not df_base.empty:
                df_analise = df_base.drop_duplicates(subset=['NCM', 'Produto', 'CFOP']).copy()
                
                # Classifica칞칚o
                resultados = df_analise.apply(
                    lambda row: classificar_item(row['NCM'], row['CFOP'], df_regras), axis=1, result_type='expand'
                )
                df_analise['Novo cClassTrib'] = resultados[0]
                df_analise['Descri칞칚o Legal'] = resultados[1]
                df_analise['Status'] = resultados[2]
                df_analise['Novo CST'] = resultados[3]
                
                # Busca na Lei Online
                if texto_lei:
                    df_analise['Citado na Lei 214?'] = df_analise['Produto'].apply(lambda x: verificar_na_lei(x, texto_lei))
                
                # Exibi칞칚o
                col1, col2 = st.columns(2)
                col1.metric("Produtos Processados", len(df_analise))
                
                # Conta quantos foram achados na lei
                achados_lei = len(df_analise[df_analise['Citado na Lei 214?'] != "-"])
                col2.metric("Produtos Citados na Lei", achados_lei, delta="Aten칞칚o" if achados_lei > 0 else None)
                
                if achados_lei > 0:
                    st.info("游댍 Encontramos termos exatos na Lei para os produtos abaixo:")
                    st.dataframe(df_analise[df_analise['Citado na Lei 214?'] != "-"][['Produto', 'Citado na Lei 214?']], use_container_width=True)
                
                st.write("### An치lise Completa")
                st.dataframe(df_analise, use_container_width=True)
                
                csv = df_analise.to_csv(index=False, sep=';', decimal=',').encode('utf-8-sig')
                st.download_button("游닌 Baixar Relat칩rio", csv, "Auditoria_Online.csv", "text/csv")
            else:
                st.warning("Nenhum dado encontrado.")